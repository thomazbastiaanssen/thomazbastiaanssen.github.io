{
  "articles": [
    {
      "path": "about.html",
      "title": "Thomaz F. S. Bastiaanssen, PhD",
      "author": [],
      "contents": "\n\n\n\nMade in R using distill and postcards.\n\n\n\n",
      "last_modified": "2025-08-06T21:28:51+02:00"
    },
    {
      "path": "CoDA_MB.html",
      "title": "Compositional Microbiome Data",
      "author": [],
      "contents": "\n\n\n\n\n\n\n\n\nThomaz F. S. Bastiaanssen, PhD\n\n\nHome\nNotes\nStats\nMedia\n☰\n\n\n  \n    \n      \n        \n        \n        \n      \n      \n    \n    \n      \n  Home\n\n\n  Notes\n\n\n  Stats\n\n\n  Media\n\n      \n  \n\n\n\n\n\n\nCompositional Microbiome Data\n\n\n\n\n\nInterpreting Centered Log-Ratio Transformed Data\nThe centered log-ratio (CLR) transformation may be the most common\napproach to deal with compositional data, such as microbiome sequencing\ndata. To help form intuition on what the CLR transformation does and how\nto interpret it, let’s start by taking a look at the mathematical\nnotation.\nLet’s say we have a microbiome sample which we will treat as a vector\ncalled \\(\\bf{x}\\) with size \\(D\\). We’ll refer to the taxa - or more\ngenerally the elements - of this vector \\(\\bf{x}\\) as \\({x}_1\\) - \\({x}_D\\). Then, CLR-transforming that vector\n\\(\\bf{x}\\) would look like this:\n\\[clr({\\mathbf{x}}) = \\left \\lbrace \\ln\n\\left (\\frac{ {x}_{1}}{G({\\mathbf{x}})} \\right), \\dots, \\ln \\left\n(\\frac{ {x}_{D}}{G({\\mathbf{x}})} \\right) \\right \\rbrace\\]\nWhere \\({G({\\bf x})}\\) is the\ngeometric mean of \\(\\bf{x}\\). Let’s go\nthrough it step by step.\nYou can calculate the geometric mean of a set of n numbers\nby multiplying them together and then taking the nth\nroot. Just like the ‘regular’ mean, the geometric mean says something\nabout the center of your data.\nEssentially what this says is that in order to get the\nCLR-transformed values of a vector, you take every element of that\nvector, divide it by the geometric mean of the entire vector and then\ntake the natural logarithm of the result and you’re done.\nWe can deduce a few things about this\ntransformation.\nFirst, since we’re taking a natural logarithm, \\(\\frac{x_{n}}{G({\\bf x})}\\) can never be\nzero as the logarithm of zero is undefined. This means that we need to\neither replace or remove every zero in our data before we use this\ntransformation. We expand on strategies for this in the main text.\nSecond, the possible range of our data has changed. Regular counts\ncan go from 0 to infinity and relative abundance data can go from 0 to\n1, but CLR-transformed data can go from negative infinity to positive\ninfinity. The logarithm of a very small number divided by a very large\nnumber will be very negative.\nThird, if \\(x_{n}\\) is exactly the\nsame as the geometric mean \\(G({\\bf\nx})\\), \\(\\frac{x_{n}}{G({\\bf\nx})}\\) will be 1 and thus \\(clr(x_{n})\\) will be 0 as the logarithm of\n1 is equal to 0. This gives us some intuition about the size of\nCLR-transformed values. Going further on this, it means that an increase\nof 1 on a CLR-transformed scale corresponds to multiplying with\ne, Euler’s number, which is approximately equal to 2.718282.\nConversely, a decrease of 1 on a CLR-transformed scale corresponds to\ndividing by e.\nFurthermore, there are a few points to keep in mind when\ninterpreting CLR-transformed values.\nFirst, the CLR-transformation is especially useful in the scenario\nwhere most features do not change, so that the geometric mean remains\nreasonably stable between your samples. If the geometric mean is very\ndifferent between your samples, you’re dividing by very different values\nbetween your samples.\nSecond, especially for microbiome sequencing experiments, we are\nusually dealing with how many reads we found for any given organism.\nTypically, we cannot relate this back to the absolute or even the\nrelative abundances of those organisms, as all microbes have their own\nmicrobe-to-reads conversion rate. Even so, the ratios between\nthe reads are still highly informative.\nThe CLR-transformation is not a perfect solution for\ncompositionality - in fact the idea of a solution to a type of data\nseems a little odd - but in practice the CLR-transformation tends to be\na handy tool on the belt of a bioinformatician. Understanding what\nexactly it does will greatly improve its utility and reduce the chance\nof misinterpreting an analysis.\n\nFurther reading:\nUnderstanding\nsequencing data as compositions: an outlook and review\nBugs as\nfeatures (part 1): concepts and foundations for the compositional data\nanalysis of the microbiome–gut–brain axis\n\n\n\nDealing with sequencing biases and batches\nRead count data from metagenomic sequencing experiments are affected\nby a multiplicative, sequence-specific bias. This is because sequences\nfrom different taxa can be subjected to vastly different conditions\nbefore sequencing and may also differ in how effectively they can be\nbound & sequenced by modern platforms.\nOften, we have no way of estimating the per-read bias. However, we do\nknow it is multiplicative (and not additive). Therefore, we can try to\nremove the bias by dividing each feature by its geometric mean. This is\nalso known as geometric mean centering.\nLet’s imagine a microbiome feature table \\(X\\), with \\(i\\) samples as rows and\n\\(j\\) features as\ncolumns:\n\\[\nX_{i,j} =\n\\begin{pmatrix}\n  x_{1,1} & x_{1,2} & x_{1,3} & \\cdots & x_{1,j} \\\\\n  x_{2,1} & x_{2,2} & x_{2,3} & \\cdots & x_{2,j} \\\\\n  x_{3,1} & x_{3,2} & x_{3,3} & \\cdots & x_{3,j} \\\\\n  \\vdots  & \\vdots  &\\vdots  & \\ddots & \\vdots  \\\\\n  x_{i,1} & x_{i,2} & x_{i,3} & \\cdots & x_{i,j}\n\\end{pmatrix}\n\\]\nBecause we are dealing with compositional data, the values themselves\nare not informative, only the ratios between values (components) within\na composition.\nWe can divide each element of \\(\\bf{x^{*}_{j}}\\) by its geometric mean\n\\(G({\\bf x^{*}_{j}})\\) to geometric\nmean center each feature. This is different from the CLR-transformation,\nas we center over the features here instead of centering over the\nsamples. In other words:\n\\[\ncentered(X_{i,j}) =\n\\begin{pmatrix}\n  \\frac{x_{1,1}}{G({\\bf x^{*}_{1}})} & \\frac{x_{1,2}}{G({\\bf\nx^{*}_{2}})} & \\frac{x_{1,3}}{G({\\bf x^{*}_{3}})} & \\cdots &\n\\frac{x_{1,j}}{G({\\bf x^{*}_{j}})} \\\\\n  \\frac{x_{2,1}}{G({\\bf x^{*}_{1}})} & \\frac{x_{2,2}}{G({\\bf\nx^{*}_{2}})} & \\frac{x_{2,3}}{G({\\bf x^{*}_{3}})} & \\cdots &\n\\frac{x_{2,j}}{G({\\bf x^{*}_{j}})} \\\\\n  \\frac{x_{3,1}}{G({\\bf x^{*}_{1}})} & \\frac{x_{3,2}}{G({\\bf\nx^{*}_{2}})} & \\frac{x_{3,3}}{G({\\bf x^{*}_{3}})} & \\cdots &\n\\frac{x_{3,j}}{G({\\bf x^{*}_{j}})} \\\\\n  \\vdots                             &\n\\vdots                             &\n\\vdots                             & \\ddots & \\vdots  \\\\\n  \\frac{x_{i,1}}{G({\\bf x^{*}_{1}})} & \\frac{x_{i,2}}{G({\\bf\nx^{*}_{2}})} & \\frac{x_{i,3}}{G({\\bf x^{*}_{3}})} & \\cdots &\n\\frac{x_{i,j}}{G({\\bf x^{*}_{j}})}\n\\end{pmatrix}\n\\] We can center microbiome data per batch to more reasonably\ncompare between batches, as we remove the batch-specific multiplicative\nbias. Additionally, centering may have favourable properties for summed\nlog-ratio analysis, where we sum together components to make\namalgamations.\nAitchison distance is invariant to centering by feature\ngeometric means:\nset.seed(1)\n#Simulate simple microbiome data with 10 features, 20 samples and 10.000 reads per sample. \ncounts <- t(rmultinom(n = 20, 10000, prob = runif(10, min = 0.01, max = 1)))\n\n#CLR-transform each sample:\ncounts.clr = t(apply(\n  counts, 1, FUN = function(x) { log(x) - mean(log(x)) }\n  ))\n\n#Alternatively, first center each feature:\ncent_counts = apply(\n  #Here I divide by the geometric mean in log-space, to avoid rounding issues with small numbers.\n  counts, 2, FUN = function(x) {exp( log(x) - mean(log(x)))} \n  )\n\n#And then CLR-transform as before:\ncent_counts.clr = t(apply(\n  cent_counts, 1, FUN = function(x) { log(x) - mean(log(x)) }\n  ))\n\n#Aitchison distance is the same:\nall.equal(\n  c(dist(counts.clr,      method = \"euclidean\")),\n  c(dist(cent_counts.clr, method = \"euclidean\"))\n  )\n## [1] TRUE\n(Meaning beta diversity will not change, nor will differential\nabundance)\n\nQuestions\nWhat does it mean to sum together centered components?\n\n\nFurther reading:\nConsistent and\ncorrectable bias in metagenomic sequencing experiments\n\n\n\n\n\n\n\n\n\n\n\n\n",
      "last_modified": "2025-08-06T21:28:51+02:00"
    },
    {
      "path": "index.html",
      "title": "Thomaz F. S. Bastiaanssen, PhD",
      "author": [],
      "contents": "\n\n          \n          \n          Thomaz F. S. Bastiaanssen, PhD\n          \n          \n          Home\n          Notes\n          Stats\n          Media\n          ☰\n          \n          \n      \n        \n          \n            \n              \n            \n              Thomaz F. S. Bastiaanssen, PhD\n            \n            \n              \n                \n                    \n                      \n                        Publications\n                      \n                    \n                  \n                                    \n                    \n                      \n                        CV\n                      \n                    \n                  \n                                    \n                    \n                      \n                        Twitter\n                      \n                    \n                  \n                                    \n                    \n                      \n                        Email\n                      \n                    \n                  \n                                    \n                    \n                      \n                        GitHub\n                      \n                    \n                  \n                                    \n                    \n                      \n                        Recipes\n                      \n                    \n                  \n                                  \n            \n          \n        \n        \n        \n          \n            Summary (click headers to\n            expand)\n            IntroductionI am a bioinformatician\n            interested in the interplay between the gut microbiome and\n            host mood and mental health.\n            The focus of my research currently lies in understanding\n            microbiome-gut-brain communication from a theoretical\n            ecology/bioinformatics perspective. In particular, I am\n            interested in understanding the role of stability and\n            volatility of the gut microbiome in anxiety and depression\n            and in integrating different types of ’omics data in a\n            biologically interpretable manner.\n            As a bioinformatician, I value clear and easily\n            interpretable analysis of complex data in order to promote\n            interdisciplinary collaboration. After working as the lead\n            bioinformatician in Prof. Cryans lab in Cork, Ireland, I\n            transitioned to a new position in Amsterdam UMC with\n            Prof. Brenda Penninx in 2024.\n            EducationUniversity College\n            Cork | Cork, Ireland PhD | 2018 - 2021\n            Supervision of Prof. John F. Cryan, Prof. Timothy G.\n            Dinan and Dr. Marcus J. Claesson\n            Utrecht University | Utrecht,\n            Netherlands MSc | 2014 - 2017\n            Trajectory: Molecular and Cellular Life Sciences -\n            Bioinformatics\n            \n            \n            BSc | 2010 - 2013\n            Major in Biology with a Minor in Art History\n            \n            ExperienceAmsterdam\n            UMC | Netherlands Postdoctoral Researcher |\n            April 2024 - Present\n            Microbiome Bioinformatician\n            \n            APC Microbiome Ireland | Cork, Ireland\n            Postdoctoral Researcher | March 2021 - March 2024\n            Lead Bioinformatician\n            \n            QR\n        \n      \n    \n\n    \n      \n        \n          \n            \n              \n            \n              Thomaz F. S. Bastiaanssen, PhD\n            \n            \n              \n                \n                                    \n                    \n                      Publications\n                    \n                  \n                                    \n                    \n                      CV\n                    \n                  \n                                    \n                    \n                      Twitter\n                    \n                  \n                                    \n                    \n                      Email\n                    \n                  \n                                    \n                    \n                      GitHub\n                    \n                  \n                                    \n                    \n                      Recipes\n                    \n                  \n                                  \n              \n            \n            \n              Summary (click headers to\n              expand)\n              IntroductionI am a bioinformatician\n              interested in the interplay between the gut microbiome and\n              host mood and mental health.\n              The focus of my research currently lies in\n              understanding microbiome-gut-brain communication from a\n              theoretical ecology/bioinformatics perspective. In\n              particular, I am interested in understanding the role of\n              stability and volatility of the gut microbiome in anxiety\n              and depression and in integrating different types of\n              ’omics data in a biologically interpretable manner.\n              As a bioinformatician, I value clear and easily\n              interpretable analysis of complex data in order to promote\n              interdisciplinary collaboration. After working as the lead\n              bioinformatician in Prof. Cryans lab in Cork, Ireland, I\n              transitioned to a new position in Amsterdam UMC with\n              Prof. Brenda Penninx in 2024.\n              EducationUniversity College\n              Cork | Cork, Ireland PhD | 2018 - 2021\n              Supervision of Prof. John F. Cryan, Prof. Timothy G.\n              Dinan and Dr. Marcus J. Claesson\n              Utrecht University | Utrecht,\n              Netherlands MSc | 2014 - 2017\n              Trajectory: Molecular and Cellular Life Sciences -\n              Bioinformatics\n              \n              \n              BSc | 2010 - 2013\n              Major in Biology with a Minor in Art History\n              \n              ExperienceAmsterdam\n              UMC | Netherlands Postdoctoral Researcher |\n              April 2024 - Present\n              Microbiome Bioinformatician\n              \n              APC Microbiome Ireland | Cork,\n              Ireland Postdoctoral Researcher | March 2021 - March\n              2024\n              Lead Bioinformatician\n              \n              QR\n        \n      \n    \n\n    \n    \n    ",
      "last_modified": "2025-08-06T21:29:18+02:00"
    },
    {
      "path": "media.html",
      "title": "Media appearances",
      "author": [],
      "contents": "\n\n\n\n\n\n\n\n\nThomaz F. S. Bastiaanssen, PhD\n\n\nHome\nNotes\nStats\nMedia\n☰\n\n\n  \n    \n      \n        \n        \n        \n      \n      \n    \n    \n      \n  Home\n\n\n  Notes\n\n\n  Stats\n\n\n  Media\n\n      \n  \n\n\n\n\n\n\nMedia appearances\n\n\n\n\n\nRadio & Podcasts:\nPRV1\n(Slovenian public radio), 2021\nThe\nBeyond Addiction Show, 2021\nISAPP,\n2024\nNPR,\n2024\n\n\nArticles\nAPC\nGUT REACTION, 2022\nAPC\nNews, 2024\nNPR,\n2024\n\n\n\n\n\n\n\n\n\n\n\n",
      "last_modified": "2025-08-06T21:29:18+02:00"
    },
    {
      "path": "sum_of_squares.html",
      "title": "Friendly linear models",
      "author": [],
      "contents": "\n\n\n\n\n\n\n\n\nThomaz F. S. Bastiaanssen, PhD\n\n\nHome\nNotes\nStats\nMedia\n☰\n\n\n  \n    \n      \n        \n        \n        \n      \n      \n    \n    \n      \n  Home\n\n\n  Notes\n\n\n  Stats\n\n\n  Media\n\n      \n  \n\n\n\n\n\n\nFriendly linear models\n\n\n\n\n\nLitany against fear of ANOVA\nI must not fear ANOVA.Fear is the mind-killer.Fear is the little-death that brings total obliteration.I will face my fear.\nI will permit it to pass over me and through me.And when it has gone past, I will turn the inner eye to see its\npath.Where the ANOVA has gone, there will be nothing. Only least-squares\nregression will remain.\n\n\nA note on notation\nWhenever we employ linear modeling techniques, we make the extremely\nconvenient assumption that we can express these models using high school\nalgebra:\n\\[\\begin{equation}\n\\tag{first style}\nf(x) = ax + b\n\\end{equation}\\]\nIf this comes as a surprise to you, it may be because we often use a\ndifferent notation for linear modeling. This is deeply confusing. The\nabove, hopefully familiar model would be expressed like this:\n\\[\\begin{equation}\n\\tag{second style}\ny \\sim \\beta_0 + \\beta_1 x\n\\end{equation}\\]\nDon’t be fooled, dear reader, the meaning behind these formulas is\nidentical. For our purposes, \\(f(x)\\)\nis just another way of saying \\(y\\).\nThe tilde (\\(\\sim\\)) should be read as\nis explained by, a more nuanced version of is equal to\n(\\(=\\)). Finally, we have \\(\\beta_0\\) and \\(\\beta_1\\), which correspond to \\(b\\) and \\(a\\) in the first formula. Note that the\norder is swapped between the two formulas. The reason for this is\nconvention: With the first notation, we use letters to mark variables,\nusually from highest to lowest power of \\(x\\). So:\n\\[\\begin{equation}\n\\tag{first style}\nf(x) = ax^3 + bx^2 + cx + d\n\\end{equation}\\]\nIn the second notation, we still use letters, but they’re all \\(\\beta\\). To tell our \\(\\beta\\)s apart we label them at their\nbottom-right, starting with \\(\\beta_0\\). Further, we typically go from\nlowest to highest order. So:\n\\[\\begin{equation}\n\\tag{second style}\ny \\sim \\beta_0 + \\beta_1x + \\beta_2x^2 + \\beta_3x^3\n\\end{equation}\\]\n\n\nLinear models\nLet’s start by taking a look at our data. We have 20 observations of\n\\(y\\), with complementary \\(x\\) values. In this particular case the\n\\(x\\)-values happen to be the integers\nfrom 1 to 20.\n\nAt this point, your instincts are hopefully screaming at you about a\npositive association between \\(y\\) and\n\\(x\\).\n\n\nTwo models for two hypotheses\nIn order to determine whether a model fits sufficiently well, perhaps\neven significantly well, we have to compare it to some sort of\nbaseline model. By convention, we refer to the baseline model as the\nnull-model. By constructing these two models, we have\nimplicitly proposed two hypothetical scenarios, two hypotheses,\nwhich are conventionally referred to as H0 and H1\nfor the null-hypothesis and often more interesting non-null, ‘actual’\nhypothesis.\nIn this example, we expect there is an association between \\(y\\) and \\(x\\). In other words, we hypothesize that\nthe ‘actual’ model is some sort of diagonal, straight line. In the\nsection above, we discussed that the formula for such a line is:\n\\[\\begin{equation}\n\\tag{$H_1$ model}\ny \\sim \\beta_0 + \\beta_1x\n\\end{equation}\\]\nConvince yourself that \\(\\beta_1x\\),\nwhich corresponds to \\(ax\\) using the\nfirst notation style, is the only part of this model that can be\naffected by \\(x\\). Further, recognize\nthat \\(\\beta_1\\) (or \\(a\\)), controls the slope of the straight\nline that is defined by this model. Now that we’ve defined our \\(H_1\\), let’s think about the null-model and\ncorresponding implicit null-hypothesis, \\(H_0\\).\nIf our \\(H_1\\) is that there is an\nassociation between \\(y\\) and \\(x\\), is seems fair that our \\(H_0\\) should be that there is no\nassociation between \\(y\\) and \\(x\\). In that case, we should expect that\nour model would perform just fine without any mention of \\(x\\). So, let’s simply kick out \\(\\beta_1x\\). What’s left will be our \\(H_0\\).\n\\[\\begin{equation}\n\\tag{$H_0$ model}\ny \\sim \\beta_0\n\\end{equation}\\]\nRecall that \\(\\beta_0\\), also known\nas \\(b\\) in the first notation style,\nis a ‘regular’, constant value that controls the \\(y\\)-values (height) of our line.\n\nCounting model parameters\nBefore we go ahead and plot our models, we’ll note down the number of\nparameters used for each of our models. \\(H_1\\) uses two (namely \\(\\beta_0\\) and \\(\\beta_1\\)), whereas \\(H_0\\) only uses one (namely, \\(\\beta_0\\)). We’ll need this information\nlater. With all this in mind, let’s take a look at the two straight\nlines our models have drawn through our data.\n\n\n\n\nResiduals\nNeither model perfectly explains the data, as not all data points lie\nprecisely on the line. We can measure how much discrepancy there is\nbetween the points and the the line. We call these discrepancies, or\nerrors, that remain after having fitted the model the\nresiduals. Note that some of the residuals are negative, while\nothers are positive. Because positive and negative residuals are equally\nbad, we’ll make them both positive. In the case of least-squares\nregression we square the values to achieve this, as the name\nimplies.\n\n\n\nSum of Squares\nNext, we want to summarize the total amount of error for both of our\nmodels. To achieve this, we’ll simply add (or sum) all the squared\nresidual errors together for both models. You may have seen the term\n‘sum-of-squares’ before. This is exactly what’s going on here. We’ll\ncall the two resulting residual sums of squares \\(RSS_0\\) and \\(RSS_1\\), for \\(H_0\\) and \\(H_1\\), respectively.\n\n\n\nCalculating the F-statistic\nNow that we have calculated the residual sums of squares (RSS) for\nboth models, we can start thinking about which model we find more\nlikely. Often, we are interested in estimating a p-value, in\nother words, an estimation of how likely our observed data would be to\nhappen, assuming that the null-hypothesis is true. We can use the F\ndistribution to calculate our p-value. We can think about the\nF-distribution as a set of shapes defined by a formula, a bit like how\nthe formula \\(f(x) = ax^2 + bx + c\\)\ndefines a set of shapes, namely parabolas. In order to figure out which\nparticular shape and corresponding p-value we have, we need to know the\nvalue of three parameters, named \\(F\\),\n\\(df_1\\) and \\(df_2\\). R then provides a wonderfully\nconvenient function, pf(), that does most of the heavy\nlifting for us. What’s more, we now have all the necessary information\nto find the values of these three parameters. The formulas for our three\nvariables are as follows:\n\\[\\begin{equation}\n\\tag{The F-distribution}\nF = \\frac{RSS_0 - RSS_1}{RSS_1}\\times \\frac{df_2}{df_1} ,\\\\\ndf_1 = p_1 - p_0 ,  \ndf_2 = n - p_1\n\\end{equation}\\]\nWhere \\(p_0\\) is the number of\nparameters in \\(H_0\\) (one), \\(P_1\\) is the number of parameters in \\(H_1\\) (two) and \\(n\\) is, well, the n-number (20). Let’s plug\nthat into our formula:\n\\[\\begin{equation}\n\\tag{Our F-value}\nF = \\frac{35.922 - 16.192}{16.192}\\times \\frac{2 - 1}{20 - 2} = 21.93\n\\end{equation}\\]\nSo, for our example, \\(F = 21.93\\),\n\\(df_1 = 1\\) and \\(df_2 = 18\\). let’s plug that into\npf() to get our p-value.\npf(21.93, 1, 18, lower.tail = FALSE)\n## [1] 0.0001852457\nLet’s compare our values to those we get when fitting an ANOVA in R\nthe regular way:\nlm(y ~ x) |> anova()\n## Analysis of Variance Table\n## \n## Response: y\n##           Df Sum Sq Mean Sq F value    Pr(>F)    \n## x          1 19.731 19.7306  21.934 0.0001851 ***\n## Residuals 18 16.192  0.8995                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nGreat! Our values correspond to those in Df,\nF value, and Pr(>F), up to rounding error.\nWe can also spot \\(RSS_1\\) in the\nSum Sq column, but \\(RSS_0\\) is not found immediately. However,\nwhen we sum together the two values in the Sum Sq column,\nwe do indeed get 35.922. Wonderful!\n\n\n\n\n\n\n\n\n\n\n\n",
      "last_modified": "2025-08-06T21:29:20+02:00"
    }
  ],
  "collections": []
}
